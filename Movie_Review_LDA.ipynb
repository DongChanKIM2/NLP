{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "01_NLP_Sklearn_LDA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrKYV51vX6XM"
      },
      "source": [
        "# 자연어처리로 영화 리뷰 분석\n",
        "자연어처리에 배우고 나서 시작한 프로젝트이다.   \n",
        "리뷰 분석을 통해 긍정/부정 및 다양한 감정을 분석할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ5E3w68ZDhN"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DongChanKIM2/NLP/blob/main/Movie_Review_LDA.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0N7PObiX6XT"
      },
      "source": [
        "## 라이브러리 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5_QalizX__R"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h2441pPX6XU"
      },
      "source": [
        "import pandas as pd # 데이터 처리\n",
        "from sklearn.feature_extraction.text import CountVectorizer # 언어를 vector로 변환"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcUzT200X6XU"
      },
      "source": [
        "train=pd.read_csv('trainstory.csv')\n",
        "test=pd.read_csv('teststory.csv')\n",
        "sample_submission=pd.read_csv('sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew5Ba424X6XV"
      },
      "source": [
        "Bag Of Words 로 텍스트를 수치 특성 벡터로 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xFCwKTfX6XV"
      },
      "source": [
        "#불용어, 단어 최대 문서 0.1로 너무 잦은 단어 제외, 가장 많이 등장하는 단어 5000개 이하\n",
        "count=CountVectorizer(stop_words='english', max_df=.1, max_features=5000)\n",
        "X=count.fit_transform(train['text'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6KwThJIX6XV"
      },
      "source": [
        "## LDA(잠재 리데클링 할당)을 통해 주제 종류 선정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE16O7iHX6XW"
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E4cMwgMX6XW"
      },
      "source": [
        "lda=LatentDirichletAllocation(n_components=10, random_state=123, learning_method='batch')\n",
        "x_authors=lda.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R28WkNoLX6XX"
      },
      "source": [
        "lda.components_.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpXXFwtnX6XX"
      },
      "source": [
        "n_top_words=5\n",
        "feature_names= count.get_feature_names()\n",
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "    print(\"토픽 %d:\" % (topic_idx+1))\n",
        "    print(\" \".join([feature_names[i]\n",
        "                   for i in topic.argsort()\\\n",
        "                   [:-n_top_words - 1:-1]]))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w__GHvbsX6XX"
      },
      "source": [
        "horror=x_authors[:,0].argsort()[::-1]\n",
        "for iter_idx, movie_idx in enumerate(horror[:3]):\n",
        "    print('\\nlooking #%d:' % (iter_idx + 1))\n",
        "    print(train['text'][movie_idx][:300],'...')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}